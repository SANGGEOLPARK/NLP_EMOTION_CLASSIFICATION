{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xQlYukixrPKu",
    "outputId": "2a4f1251-c432-4ed3-cd93-6feb9fad26a7"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kkrL4nLgI0c2",
    "outputId": "65cc5e37-244d-4a3e-f1a5-dcd2465e095f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'nsmc' already exists and is not an empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000, 3)\n",
      "(50000, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import keras\n",
    "import sys\n",
    "import pickle\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import konlpy\n",
    "from konlpy.tag import Kkma\n",
    "kkma = Kkma(max_heap_size= 1024 * 6)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score,learning_curve\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "!git clone https://github.com/e9t/nsmc.git\n",
    "\n",
    "train = pd.read_csv(\"nsmc/ratings_train.txt\", sep='\\t')\n",
    "test = pd.read_csv(\"nsmc/ratings_test.txt\", sep='\\t')\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2w_pRg0cImf8"
   },
   "outputs": [],
   "source": [
    "okt=Okt()\n",
    "iter=0\n",
    "def tokenize_data(sentence:str, ner=0)->list:\n",
    "    x_tok=[]\n",
    "    if ner == 1:\n",
    "        try:\n",
    "            parsed = recognizer(sentence)\n",
    "        except:\n",
    "            return [\"없음\"]\n",
    "        \n",
    "        c=parsed[0].getEntities()\n",
    "        dic={}\n",
    "        for i in  c:\n",
    "            dic[i.getSurface()]=i.getFineLabel()\n",
    "    try:\n",
    "        a=okt.pos(sentence)\n",
    "        b=np.array(a)\n",
    "        c=(b[:,1] =='Noun')|(b[:,1] =='Adjective')|(b[:,1] =='KoreanParticle')|(b[:,1] =='Verb')|(b[:,1] =='Adverb')|(b[:,1] =='Exclamation')|(b[:,1] =='Conjunction')\n",
    "        d=b[c,0]\n",
    "        for word in d:\n",
    "            if ner==1:\n",
    "                if dic.get(word):\n",
    "                    x_tok.append(dic[word])\n",
    "                else:\n",
    "                    x_tok.append(word)\n",
    "            else:\n",
    "                x_tok.append(word)\n",
    "    except:\n",
    "        return [\"없음\"]       \n",
    "    return x_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FK95E05zImf-"
   },
   "outputs": [],
   "source": [
    "def get_nouns(text:str) -> list:\n",
    "    \"\"\" transform text to list\n",
    "    : text : one news\n",
    "    \"\"\"\n",
    "    nouns = kkma.nouns(text)\n",
    "    return [n for n in nouns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3PR2NYCvImf_"
   },
   "outputs": [],
   "source": [
    "train=train.dropna()\n",
    "train=train.drop_duplicates()\n",
    "test=test.dropna()\n",
    "test=test.drop_duplicates()\n",
    "\n",
    "traindata = train[['document','label']]\n",
    "testdata = test[['document','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fA3b3XgWImf_"
   },
   "outputs": [],
   "source": [
    "train_x=traindata.document\n",
    "train_y=traindata.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "XGj_WxuOImgA"
   },
   "outputs": [],
   "source": [
    "test_x=testdata.document\n",
    "test_y=testdata.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 각 모델 생성 및 결과 도출 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "ZEXpz8xgImgA"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=tokenize_data)),  # bow로 word2vec\n",
    "    ('tfidf', TfidfTransformer(use_idf=False)),  # weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # 나이브베이즈 분류기\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 13s\n"
     ]
    }
   ],
   "source": [
    "%time model_nb = pipeline.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_nb=model_nb.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 나이브 베이즈 모델 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85     24826\n",
      "           1       0.85      0.84      0.85     25171\n",
      "\n",
      "    accuracy                           0.85     49997\n",
      "   macro avg       0.85      0.85      0.85     49997\n",
      "weighted avg       0.85      0.85      0.85     49997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(test_y, predictions_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['naive.joblib']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model_nb, 'naive.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "VF-347HRImgD"
   },
   "outputs": [],
   "source": [
    "pipeline_logistic=Pipeline([\n",
    "            ('bow', CountVectorizer(tokenizer=tokenize_data)),\n",
    "            ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "            ('classifier', LogisticRegression(solver='newton-cg'))\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "OWqRvlfhImgE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 18s\n"
     ]
    }
   ],
   "source": [
    "%time model_logistic=pipeline_logistic.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_logistic=model_logistic.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 로지스틱 리그레션 모델 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "vrQjVN9oTnPW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84     24826\n",
      "           1       0.85      0.82      0.84     25171\n",
      "\n",
      "    accuracy                           0.84     49997\n",
      "   macro avg       0.84      0.84      0.84     49997\n",
      "weighted avg       0.84      0.84      0.84     49997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(test_y, predictions_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "pOpfA2q6TrII"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic.joblib']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model_logistic, 'logistic.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_randomforest=Pipeline([\n",
    "            ('bow', CountVectorizer(tokenizer=tokenize_data, ngram_range=(1,2))),\n",
    "            ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "            ('classifier', RandomForestClassifier(n_estimators=100, oob_score=True))\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2h 37min 52s\n"
     ]
    }
   ],
   "source": [
    "%time model_randomforest=pipeline_randomforest.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_randomforest=model_randomforest.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 랜덤 포레스트 모델 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82     24826\n",
      "           1       0.83      0.82      0.82     25171\n",
      "\n",
      "    accuracy                           0.82     49997\n",
      "   macro avg       0.82      0.82      0.82     49997\n",
      "weighted avg       0.82      0.82      0.82     49997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(test_y, predictions_randomforest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['randomforest.joblib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model_randomforest, 'randomforest.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_gdboost=Pipeline([\n",
    "            ('bow', CountVectorizer(tokenizer=tokenize_data)),\n",
    "            ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "            ('classifier', GradientBoostingClassifier(random_state=0, max_depth=3, learning_rate=0.1))\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 7s\n"
     ]
    }
   ],
   "source": [
    "%time model_gdboost=pipeline_gdboost.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_gdboost=model_gdboost.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그라디언트부스트 모델 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.88      0.75     24826\n",
      "           1       0.82      0.53      0.64     25171\n",
      "\n",
      "    accuracy                           0.70     49997\n",
      "   macro avg       0.73      0.70      0.69     49997\n",
      "weighted avg       0.73      0.70      0.69     49997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(test_y, predictions_gdboost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gdboost.joblib']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model_gdboost, 'gdboost.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_nb, model_logistic, model_gdboost, model_randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_result (result):\n",
    "    ret=[]\n",
    "    for i in result:\n",
    "        onehot=[0,0]\n",
    "        onehot[i]=1\n",
    "        ret.append(onehot)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가 데이터 전처리 및  VOTE 결과 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "leader_test = pd.read_csv(\"ko_data.csv\",encoding='CP949')\n",
    "leader_test= leader_test.rename(columns={'Sentence':'document'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "leader_test=leader_test['document']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1=model_nb.predict(leader_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2=model_logistic.predict(leader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3=model_gdboost.predict(leader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "result4=model_randomforest.predict(leader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1=one_hot_result(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2=one_hot_result(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3=one_hot_result(result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "result4=one_hot_result(result4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tot_onehot=np.array(result1)+np.array(result2)+np.array(result3)+np.array(result4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_onehot=np.array(result1)+np.array(result2)+np.array(result4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_result=np.argmax(tot_onehot, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "f = open('sample_ensemble.csv','a', newline='')\n",
    "wr = csv.writer(f)\n",
    "wr.writerow(['Id','Predicted'])\n",
    "for i in range(len(tot_result)):\n",
    "  wr.writerow([i,tot_result[i]])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "TF-IDF_NAIVE_KOR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
